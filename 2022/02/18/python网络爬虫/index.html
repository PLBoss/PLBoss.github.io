<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <!--Description-->

    

    
        <meta name="description" content="爬虫介绍*

万物皆可APIAPI:程序之间的接口
编程环境安装requests库的安装：
以管理员权限打开管理员控制台（cmd)
然后输入命令 pip install requests

测试requests库是否安装成功打开python的ide
输入以下命令：
    import requet"/>
    

    <!--Author-->
    
        <meta name="author" content="John Doe"/>
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="python网络爬虫"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="爬虫介绍*

万物皆可APIAPI:程序之间的接口
编程环境安装requests库的安装：
以管理员权限打开管理员控制台（cmd)
然后输入命令 pip install requests

测试requests库是否安装成功打开python的ide
输入以下命令：
    import requet"/>
    

    <!--Open Graph Site Name-->
        <meta property="og:site_name" content="Hexo"/>

    <!--Type page-->
    
        <meta property="og:type" content="article"/>
    

    <!--Page Cover-->
    
    
        <meta property="og:image" content="http://example.comimg/home-bg.jpg"/>
    

        <meta name="twitter:card" content="summary_large_image"/>

    

    
        <meta name="twitter:image" content="http://example.comimg/home-bg.jpg"/>
    

    <!-- Title -->
    
    <title>python网络爬虫 - Hexo</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css"/>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet"/>

    <!-- Google Analytics -->
    


    <!-- favicon -->
    

<meta name="generator" content="Hexo 5.4.0"></head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Configurable Title</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/archives">
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags">
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/categories">
                            
                                Categories
                            
                        </a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://github.com/klugjo/hexo-theme-clean-blog">
                            
                                <i class="fa fa-github fa-stack-2x"></i>
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>python网络爬虫</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                        
                            2022-02-18
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <h3 id="爬虫介绍"><a href="#爬虫介绍" class="headerlink" title="爬虫介绍"></a>爬虫介绍</h3><pre><code>*
</code></pre>
<h3 id="万物皆可API"><a href="#万物皆可API" class="headerlink" title="万物皆可API"></a>万物皆可API</h3><p>API:程序之间的接口</p>
<h3 id="编程环境安装"><a href="#编程环境安装" class="headerlink" title="编程环境安装"></a>编程环境安装</h3><pre><code>requests库的安装：
以管理员权限打开管理员控制台（cmd)
然后输入命令 pip install requests
</code></pre>
<h4 id="测试requests库是否安装成功"><a href="#测试requests库是否安装成功" class="headerlink" title="测试requests库是否安装成功"></a>测试requests库是否安装成功</h4><pre><code>打开python的ide
输入以下命令：
    import requets
    r = requests.get(&quot;http://www.baidu.com&quot;)
    print(r.status_code)
然后运行命令，显示200，则表示requests库安装成功
</code></pre>
<h4 id="requests库的主要方法"><a href="#requests库的主要方法" class="headerlink" title="requests库的主要方法"></a>requests库的主要方法</h4><pre><code>requests.get(url):含有浏览器返回的所有信息
    r=requests.get(url)
    r.status_code //返回状态，200表述连接成功，404表述连接失败
    r.text //返回url对应的页面内容
    r.encoding 返回响应内编码方式
    r.apparent_encoding 从内容这分出析响应的编码方式
    r.content 以二进制返回网页内容
    r.raise_for_status() 异常处理，如果状态不是200则会引发异常
requests.head()

requests.post()
requests.put()
requests.patch()
requests.delete()
requests.request(method,url,**kwargs)
method:get,post,put,patch,delete
**kwarges:传输数据
</code></pre>
<h3 id="网页爬取通用框架"><a href="#网页爬取通用框架" class="headerlink" title="网页爬取通用框架"></a>网页爬取通用框架</h3><pre><code>import requests
try:
 r=requests.request(get,url,timeout=30)
 r.raise_for_status()
 r.encoding=r.apprent_encoding
  return r.text
except:
    return &quot;error&quot;
</code></pre>
<h3 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h3><p>超文本传输协议<br>提取服务器信息：get head<br>更新服务器操作： post put(覆盖原有信息) patch（更新局部信息）<br>delete.<br>详见：<a target="_blank" rel="noopener" href="https://www.runoob.com/http/http-status-codes.html">https://www.runoob.com/http/http-status-codes.html</a></p>
<h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><p>是一种存储在用户本地终端的加密数据<br>作用：辨别用户身份</p>
<h3 id="robots协议"><a href="#robots协议" class="headerlink" title="robots协议"></a>robots协议</h3><p>用于网络爬虫排除标准<br>告知所有的网络爬虫爬取资源的权限</p>
<h3 id="模拟浏览器向服务器发送请求（规避浏览器来源审查）"><a href="#模拟浏览器向服务器发送请求（规避浏览器来源审查）" class="headerlink" title="模拟浏览器向服务器发送请求（规避浏览器来源审查）"></a>模拟浏览器向服务器发送请求（规避浏览器来源审查）</h3><h4 id="查看我们发给服务器的headers"><a href="#查看我们发给服务器的headers" class="headerlink" title="查看我们发给服务器的headers"></a>查看我们发给服务器的headers</h4><pre><code>r.request.headers
</code></pre>
<p>1.构造我们要模拟浏览器的headers键值对.  </p>
<pre><code>kv = &#123;&#39;user-agent&#39;:&#39;Mozilla/5.0&#39;&#125;
</code></pre>
<p>2.修改headers的user-agent字段</p>
<pre><code>r =requests.get(url,headers=kv&#125;
</code></pre>
<h3 id="关键字提交"><a href="#关键字提交" class="headerlink" title="关键字提交"></a>关键字提交</h3><pre><code>kv=&#123;:&#125;
r=requsts.get(url,params=kv)
</code></pre>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="保存文件"><a href="#保存文件" class="headerlink" title="保存文件"></a>保存文件</h2><pre><code>with open(path,&#39;wb&#39;) as f
f.write(r.content)
f.cloce
</code></pre>
<h2 id="BeautifulSoup"><a href="#BeautifulSoup" class="headerlink" title="BeautifulSoup"></a>BeautifulSoup</h2><h4 id="beautifulsoup的安装"><a href="#beautifulsoup的安装" class="headerlink" title="beautifulsoup的安装"></a>beautifulsoup的安装</h4><p>以管理员权限打开cmd ，然后输入一下命令</p>
<pre><code>pip install beautifulsoup4
</code></pre>
<h4 id="beatifulsoup的使用"><a href="#beatifulsoup的使用" class="headerlink" title="beatifulsoup的使用"></a>beatifulsoup的使用</h4><p>导入beautifulsoup库</p>
<pre><code>from bs4 import BeautifulSoup
</code></pre>
<p>对页面内容进行解析</p>
<pre><code>demo=r.text
soup=BeautifulSoup(demo,&#39;html.parser&#39;)
</code></pre>
<p>prettify的使用</p>
<pre><code>soup.prettiy()//为html文本增加换行符，分行显示
</code></pre>
<p>其中html.parser为html页面的解析器，还可以为lxml,xml,html5lib</p>
<p>获取html页面对应标签的内容</p>
<pre><code>soup.a
soup.a.string//返回a标签中的字符串类容
soup.div
soup.body
</code></pre>
<p>获取对应标签的名字</p>
<pre><code>soup.a.name
soup.parent.name
</code></pre>
<p>查看标签的属性</p>
<pre><code>tag=soup.a
tag.attrs//获取整个标签属性字典
tag.attrs[&#39;class&#39;]//查看标签a的类名
tag.attrs[&#39;id&#39;]
tag.attrs[&#39;herf&#39;]//查看标签中的链接
</code></pre>
<p>查看子节点</p>
<pre><code>soup.body.contents//查看body中所有儿子节点，将所有的儿子节点存入列表中
soup.body.children //循环遍历所有的儿子节点
soup.descendants  //用于遍历所有子孙节点
</code></pre>
<p>查看父亲节点</p>
<pre><code>soup.body.parent
soup.body.parents//用于遍历所有先辈节点
</code></pre>
<p>查看平行标签</p>
<p>查看平行标签的下一个标签</p>
<pre><code>soup.a.next_sibling//查看a标签的下一个标签
</code></pre>
<p>查看平行标签的上一个标签</p>
<pre><code>soup.a.previous_sibing//查看a标签的上一个标签
</code></pre>
<p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220224220339.png"></p>
<h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><h2 id="信息标记的三种方式"><a href="#信息标记的三种方式" class="headerlink" title="信息标记的三种方式"></a>信息标记的三种方式</h2><h3 id="xml（与html相似）"><a href="#xml（与html相似）" class="headerlink" title="xml（与html相似）"></a>xml（与html相似）</h3><p>主要用来internet上的信息交互与传递</p>
<h3 id="jason-键值对-含有双引号）"><a href="#jason-键值对-含有双引号）" class="headerlink" title="jason(键值对,含有双引号）"></a>jason(键值对,含有双引号）</h3><p>主要应用于云端和节点的信息通信<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220228201941.png"><br>可以在键值对中嵌套键值对</p>
<h3 id="Yaml-键值对形式，但无双引号）"><a href="#Yaml-键值对形式，但无双引号）" class="headerlink" title="Yaml(键值对形式，但无双引号）"></a>Yaml(键值对形式，但无双引号）</h3><p>各类系统的配置文件<br>利用缩进来表示所属关系<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220228202037.png"><br>利用减号表述所属关系<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220228202201.png"><br>用竖线表示整块数据<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220228202330.png"></p>
<h2 id="信息提取的一般方法"><a href="#信息提取的一般方法" class="headerlink" title="信息提取的一般方法"></a>信息提取的一般方法</h2><h3 id="形式解析与搜索方法"><a href="#形式解析与搜索方法" class="headerlink" title="形式解析与搜索方法"></a>形式解析与搜索方法</h3><h4 id="方法find-all的使用"><a href="#方法find-all的使用" class="headerlink" title="方法find_all的使用"></a>方法find_all的使用</h4><pre><code>soup.find_all(&#39;a&#39;)//查找所有的a标签,默认查找所有的子孙
soup.find_all(&#39;a&#39;，recursive=false)//查找所有的a标签,查找子节点
soup.find_all(&#39;a&#39;,&#39;b&#39;)//查找a和b标签

for tag in soup.find_all(True):
    print(tag.name)//查看html页面的所有内容

for tag in soup.find_all(re.compile(&#39;b&#39;)):
    print(tag.name)//查看html页面的所有以b开头的内容
sou.find_all(&#39;a&#39;,&#39;student&#39;)//查找a标签中包含student属性的标签
soup.find_all(id=&#39;link1&#39;) //查看标签中属性包含id=&#39;link1&#39;
soup.find_all(string =re.compile (&quot;python&quot;))//检索所有包含字符串python的字符串
</code></pre>
<h2 id="正则表达式（表示了一组字符串的特征或模式）"><a href="#正则表达式（表示了一组字符串的特征或模式）" class="headerlink" title="正则表达式（表示了一组字符串的特征或模式）"></a>正则表达式（表示了一组字符串的特征或模式）</h2><h3 id="导入正则表达式库"><a href="#导入正则表达式库" class="headerlink" title="导入正则表达式库"></a>导入正则表达式库</h3><pre><code>import re
</code></pre>
<h3 id="常用正则"><a href="#常用正则" class="headerlink" title="常用正则"></a>常用正则</h3><pre><code>py+//匹配以p开头且后面有一个或无穷多个y的字符串
</code></pre>
<p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220310195658.png"></p>
<h3 id="常用操作符"><a href="#常用操作符" class="headerlink" title="常用操作符"></a>常用操作符</h3><p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220310195430.png"><br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220310195518.png"></p>
<pre><code>re.sub(pattern,repl,string)//将string中符合pattern的字符串使用repl进行替换
re.finiditer(pattern,string) //将匹配到的字符串整成一个可以循环的列表，使用for循环可以取出其中的元素
re.compile(pattern) 将正则表达式的字符串形式编译成正则表达式对象
martch.group(0) //获得匹配后的字符串
martch.start() //获取匹配到的开始位置
martch.end() //匹配的结束位置
marth.spand() //匹配文本的开始与结束
martch.string //待匹配的文本
martch.re //获取匹配的正则表达式
martch.pos //获取开始匹配的位置
martch.endpos //获取结束匹配的位置
</code></pre>
<h4 id="面向对象re库用法"><a href="#面向对象re库用法" class="headerlink" title="面向对象re库用法"></a>面向对象re库用法</h4><p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220310201212.png"><br>经过一次编译，以后都可以直接使用，以此加快程序的运行    </p>
<p>###re函数的主要功能</p>
<p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220310195121.png"></p>
<h3 id="re库的贪婪匹配和最小匹配"><a href="#re库的贪婪匹配和最小匹配" class="headerlink" title="re库的贪婪匹配和最小匹配"></a>re库的贪婪匹配和最小匹配</h3><p>re库默认的是贪婪匹配，返回匹配到的最长的字符串<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220310203514.png"></p>
<hr>
<h2 id="lxml库"><a href="#lxml库" class="headerlink" title="lxml库"></a>lxml库</h2><p>官方文档 <a target="_blank" rel="noopener" href="https://www.w3cschool.cn/lxml/">https://www.w3cschool.cn/lxml/</a></p>
<h3 id="Scapy爬虫框架-5-2）"><a href="#Scapy爬虫框架-5-2）" class="headerlink" title="Scapy爬虫框架(5+2）"></a>Scapy爬虫框架(5+2）</h3><h4 id="Scrapy的安装"><a href="#Scrapy的安装" class="headerlink" title="Scrapy的安装"></a>Scrapy的安装</h4><pre><code>pip install Scrapy
</code></pre>
<h4 id="Scrapy的框架"><a href="#Scrapy的框架" class="headerlink" title="Scrapy的框架"></a>Scrapy的框架</h4><p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220316195813.png"></p>
<p>Spider</p>
<ul>
<li>解析Downloader返回的响应(Response)</li>
<li>产生爬取项(scraped item)</li>
<li>产生额外的爬取请求（Requests)</li>
</ul>
<p>Engine </p>
<ul>
<li>控制所有模块之间的数据流</li>
<li>根据条件触发事件</li>
<li>不需要用户修改</li>
</ul>
<p>DownLoader</p>
<ul>
<li>根据请求下载网页</li>
<li>不需要用户修改</li>
</ul>
<p>Scheduler </p>
<ul>
<li>不需要用户修改</li>
<li>对所有请求进行调度管理</li>
</ul>
<h4 id="Scapy常用命令"><a href="#Scapy常用命令" class="headerlink" title="Scapy常用命令"></a>Scapy常用命令</h4><p>格式：scrapy command options args</p>
<pre><code>scrapy startprojects name dir /创建一个工程
scrapy genspider name domain //创建一个爬虫
scrapy seting options //获取爬虫的配置信息
scrapy crawl spider //运行一个爬虫
scrapy list // 列出工程中所有的爬虫
scrapy shell url //启动URL调试命令行
</code></pre>
<h4 id="Scrapy基础"><a href="#Scrapy基础" class="headerlink" title="Scrapy基础"></a>Scrapy基础</h4><p>#####第一步：创建scrapy项目</p>
<p>在自己创建存储项目的文件夹内，按住shift然后右键，选择打开powershell 命令台，前面的两个单词是创建项目固定的，最后一个单词是项目名称</p>
<p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317211436.png"><br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317212010.png"></p>
<pre><code>scrapy startproject python123demo
</code></pre>
<p>#####第二步：产生demo.py<br>继续在命令台上输入 scrapy genspider python123.io ,前两个单词固定，后面是爬取页面的原始地址，这个可以在创建demo后，修改爬取网页的地址<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317212221.png"><br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317212043.png"></p>
<p>#####第三步：修改demo</p>
<p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317213550.png"></p>
<p>#####第四步：运行爬虫<br>继续在命令台输入 scrapy crawl demo<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317212523.png"></p>
<p>#####结果：<br><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220317213244.png"></p>
<h4 id="yield生成器"><a href="#yield生成器" class="headerlink" title="yield生成器"></a>yield生成器</h4><ul>
<li>生成器是一个不断产生值的函数</li>
<li>包含yild语句的函数是一个生成器</li>
<li>生成器每次产生一个值（yield语句），函数被冻结，被唤醒后在产生一个值，唤醒后还是从上一个执行的位置开始执行</li>
<li>经常与循环搭配使用<h4 id="使用实列"><a href="#使用实列" class="headerlink" title="使用实列"></a>使用实列</h4>  def gen(n):<pre><code>  for i in range(n):
      yield i**2
</code></pre>
  for i in gen(5):<pre><code>      print(i,&quot;&quot;,end=&quot;&quot;)
</code></pre>
  结果： 0 1 4 9 16</li>
</ul>
<p>#####生成器的优点（相比与普通的列表返回方法）</p>
<ul>
<li>更快的响应速度</li>
<li>更节省存储空间（每次只需要一个存储空间）</li>
<li>使用更加灵活</li>
</ul>
<h4 id="爬虫的生成器写法"><a href="#爬虫的生成器写法" class="headerlink" title="爬虫的生成器写法"></a>爬虫的生成器写法</h4><pre><code>for url in start_urls:
        yield scrapy.Request(url=url,callback=self.parse)
</code></pre>
<h4 id="scrapy爬虫的使用步骤"><a href="#scrapy爬虫的使用步骤" class="headerlink" title="scrapy爬虫的使用步骤"></a>scrapy爬虫的使用步骤</h4><p>步骤一：创建一个工程和spider模板<br>步奏二:编写spider<br>步骤三： 编写item pipecline<br>步骤四： 优化配置策略</p>
<h5 id="Scrapy爬虫的数据类型"><a href="#Scrapy爬虫的数据类型" class="headerlink" title="Scrapy爬虫的数据类型"></a>Scrapy爬虫的数据类型</h5><p>Ruests类 </p>
<pre><code>class scrapy.http.Request()
</code></pre>
<table>
<thead>
<tr>
<th>.url</th>
<th>.method</th>
<th>.headers</th>
<th>.body</th>
<th>.meta</th>
<th>.copy</th>
</tr>
</thead>
<tbody><tr>
<td>requests对应请求的位置</td>
<td>对应的请求方法</td>
<td>字典类型的请求头</td>
<td>内容的主体</td>
<td>用户添加的拓展信息</td>
<td>复制该请求</td>
</tr>
</tbody></table>
<p>Response类  </p>
<pre><code>class scrapy.http.Response()
</code></pre>
<p><img src="https://plboss-imges.oss-cn-chengdu.aliyuncs.com/master/20220321212306.png"></p>
<p>Item类 </p>
<pre><code> class scrapy.http.Response()
</code></pre>
<h5 id="Css-selector"><a href="#Css-selector" class="headerlink" title="Css-selector"></a>Css-selector</h5><pre><code>&lt;HTML&gt;.CSS(&#39;a::attr(herf)&#39;).extract()
</code></pre>


                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    

                    
                        <li>
                            <a href="https://github.com/klugjo/hexo-theme-clean-blog" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2023 John Doe<br></p>
                <p class="copyright text-muted">Original Theme <a target="_blank" href="http://startbootstrap.com/template-overviews/clean-blog/">Clean Blog</a> from <a href="http://startbootstrap.com/" target="_blank">Start Bootstrap</a></p>
                <p class="copyright text-muted">Adapted for <a target="_blank" href="https://hexo.io/">Hexo</a> by <a href="http://www.codeblocq.com/" target="_blank">Jonathan Klughertz</a></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>